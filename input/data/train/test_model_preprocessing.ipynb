{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "348a66c2-cc4b-4bc2-b8fc-bc35d11d27a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import time\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd3da1b8-8580-4eb6-a6af-d1e623334e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53338497-fa5c-45c8-ba97-d2312be90c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "17cd53a8-7504-4a75-ab94-1f21bbddc6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TRAIN_CDataset(Dataset):\n",
    "    def __init__(self,train=True):\n",
    "        self.df = pd.read_csv('./train_label.csv')\n",
    "        #self.X = Image.open('./images/' + self.df.loc[idx]['path'] + '/' + self.df.loc[idx]['fname'])\n",
    "        #self.y = self.df.loc[idx]['label']\n",
    "        #self.d_idx = d_index\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self,idx):\n",
    "        #data_index = self.d_idx\n",
    "        X = Image.open('./images/' + self.df.loc[idx]['path'] + '/' + self.df.loc[idx]['fname'])\n",
    "        X = transforms.CenterCrop(270)(X)\n",
    "        y = self.df.loc[idx]['label'] \n",
    "        #print(y)\n",
    "        X = transforms.ToTensor()(X)\n",
    "        y = torch.tensor(y)\n",
    "        return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6e07f796-32fa-42dc-863d-bdec6e930f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TEST_CDataset(Dataset):\n",
    "    def __init__(self,train=True):\n",
    "        self.df = pd.read_csv('./test_label.csv')\n",
    "        #self.X = Image.open('./images/' + self.df.loc[idx]['path'] + '/' + self.df.loc[idx]['fname'])\n",
    "        #self.y = self.df.loc[idx]['label']\n",
    "        #self.d_idx = d_index\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self,idx):\n",
    "        #data_index = self.d_idx\n",
    "        X = Image.open('./images/' + self.df.loc[idx]['path'] + '/' + self.df.loc[idx]['fname'])\n",
    "        X = transforms.CenterCrop(270)(X)\n",
    "        y = self.df.loc[idx]['label'] \n",
    "        #print(y)\n",
    "        X = transforms.ToTensor()(X)\n",
    "        y = torch.tensor(y)\n",
    "        return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cfcc75db-4bd9-4589-9f4f-32128f6ae3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TRAIN_CDataset(train=True)\n",
    "test_ds = TEST_CDataset(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "034ae3d8-d095-49f8-90fd-8d6d844814c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds,\n",
    "                      batch_size=16,\n",
    "                      shuffle=True,\n",
    "                      num_workers=1,\n",
    "                     drop_last=True)\n",
    "test_dl = DataLoader(test_ds,\n",
    "                     batch_size=16,\n",
    "                     shuffle=True,\n",
    "                     num_workers=1,\n",
    "                    drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "40d30cc4-a295-4e91-af0c-710030e7e7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.residual_function = nn.Sequential(nn.Conv2d(in_channels, out_channels,kernel_size=3,\n",
    "                                                         stride=stride, padding=1, bias=False),\n",
    "                                               nn.BatchNorm2d(out_channels),\n",
    "                                               nn.ReLU(),\n",
    "                                               nn.Conv2d(out_channels, out_channels * BasicBlock.expansion,\n",
    "                                                         kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                               nn.BatchNorm2d(out_channels * BasicBlock.expansion),)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:\n",
    "            self.shortcut = nn.Sequential(nn.Conv2d(in_channels, out_channels * BasicBlock.expansion,\n",
    "                                                    kernel_size=1, stride=stride, bias=False),\n",
    "                                          nn.BatchNorm2d(out_channels * BasicBlock.expansion))\n",
    "    def forward(self,x):\n",
    "        x = self.residual_function(x) + self.shortcut(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cd52fb7e-900f-4eb6-8237-253679e366c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleNeck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.residual_function = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=1,\n",
    "                                                         stride=1,bias=False),\n",
    "                                               nn.BatchNorm2d(out_channels),\n",
    "                                               nn.ReLU(),\n",
    "                                               nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                                                         stride=stride, padding=1, bias=False),\n",
    "                                               nn.BatchNorm2d(out_channels),\n",
    "                                               nn.ReLU(),\n",
    "                                               nn.Conv2d(out_channels, out_channels * BottleNeck.expansion,\n",
    "                                                         kernel_size=1, stride=1, bias=False),\n",
    "                                               nn.BatchNorm2d(out_channels * BottleNeck.expansion),)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
    "            self.shortcut = nn.Sequential(nn.Conv2d(in_channels, out_channels * BottleNeck.expansion,\n",
    "                                                     kernel_size=1, stride=stride, bias=False),\n",
    "                                           nn.BatchNorm2d(out_channels * BottleNeck.expansion))\n",
    "            \n",
    "    def forward(self,x):\n",
    "        x = self.residual_function(x) + self.shortcut(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "34167ec1-0ae2-498d-88c3-2c59a63e1874",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_block, num_classes=18, init_weights=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels=64\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
    "        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
    "        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
    "        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        # weights inittialization\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.conv2_x(output)\n",
    "        x = self.conv3_x(output)\n",
    "        x = self.conv4_x(x)\n",
    "        x = self.conv5_x(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    # define weight initialization function\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0665bc60-c8bd-4696-8963-048cc6ed2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])\n",
    "def resnet34():\n",
    "    return ResNet(BasicBlock, [3,4,6,3])\n",
    "def resnet50():\n",
    "    return ResNet(BottleNeck, [3,4,6,3])\n",
    "def resnet101():\n",
    "    return ResNet(BottleNeck, [3,4,23,3])\n",
    "def resnet152():\n",
    "    return ResNet(BottleNeck, [3,8,36,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "89e87e27-29e3-47e2-a168-80b13feb2802",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a07b9bf3-e38a-4643-a9b0-e94d945c0ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = resnet50().to(device)\n",
    "#x = torch.randn(3,3,244,244).to(device)\n",
    "#output = model(x)\n",
    "#print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "04bc9e52-71f2-4717-ab78-14bd3b7b1764",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss(reduction='sum')\n",
    "opt = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "lr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9105564f-4e48-4f34-9e67-1eb496668b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(opt):\n",
    "    for param_group in opt.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "50a48861-28ee-4cbd-83c0-7f32d371efef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_batch(output, target):\n",
    "    pred = output.argmax(1, keepdim=True)\n",
    "    corrects = pred.eq(target.view_as(pred)).sum().item()\n",
    "    return corrects\n",
    "\n",
    "def loss_batch(loss_func, output, target, opt=None):\n",
    "    loss = loss_func(output, target)\n",
    "    metric_b = metric_batch(output, target)\n",
    "    \n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "    return loss.item(), metric_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7fc72381-a997-468c-b8ca-0fd70a26d08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n",
    "    running_loss = 0.0\n",
    "    running_metric = 0.0\n",
    "    len_data = len(dataset_dl.dataset)\n",
    "\n",
    "    for xb, yb in dataset_dl:\n",
    "        xb = xb.to(device)\n",
    "\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        output = model(xb)\n",
    "\n",
    "\n",
    "        loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n",
    "\n",
    "        running_loss += loss_b\n",
    "        \n",
    "        if metric_b is not None:\n",
    "            running_metric += metric_b\n",
    "        \n",
    "        if sanity_check is True:\n",
    "            break\n",
    "\n",
    "    loss = running_loss / len_data\n",
    "    metric = running_metric / len_data\n",
    "\n",
    "    return loss, metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3368c10f-41f9-411f-8876-ba512dda2874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val(model, params):\n",
    "    num_epochs=params['num_epochs']\n",
    "    loss_func=params[\"loss_func\"]\n",
    "    opt=params[\"optimizer\"]\n",
    "    train_dl=params[\"train_dl\"]\n",
    "    test_dl=params[\"test_dl\"]\n",
    "    sanity_check=params[\"sanity_check\"]\n",
    "    lr_scheduler=params[\"lr_scheduler\"]\n",
    "    path2weights=params[\"path2weights\"]\n",
    "\n",
    "    loss_history = {'train': [], 'val': []}\n",
    "    metric_history = {'train': [], 'val': []}\n",
    "\n",
    "    # # GPU out of memoty error\n",
    "    #print(model.state_dict())\n",
    "    #best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        current_lr = get_lr(opt)\n",
    "        print('Epoch {}/{}, current lr={}'.format(epoch, num_epochs-1, current_lr))\n",
    "\n",
    "        model.train()\n",
    "        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n",
    "        loss_history['train'].append(train_loss)\n",
    "        metric_history['train'].append(train_metric)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_metric = loss_epoch(model, loss_func, test_dl, sanity_check)\n",
    "        loss_history['val'].append(val_loss)\n",
    "        metric_history['val'].append(val_metric)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            #print(model.state_dict())\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            #best_model_wts = model.state_dict()\n",
    "\n",
    "            #torch.save(model.state_dict(), path2weights)\n",
    "            #print('Copied best model weights!')\n",
    "            print('Get best val_loss')\n",
    "\n",
    "        lr_scheduler.step(val_loss)\n",
    "\n",
    "        print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
    "        print('-'*10)\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model, loss_history, metric_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d9e045c2-1286-4a93-839c-59879e44f71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definc the training parameters\n",
    "params_train = {\n",
    "    'num_epochs':15,\n",
    "    'optimizer':opt,\n",
    "    'loss_func':loss_func,\n",
    "    'train_dl':train_dl,\n",
    "    'test_dl':test_dl,\n",
    "    'sanity_check':False,\n",
    "    'lr_scheduler':lr_scheduler,\n",
    "    'path2weights':'./weights.pt',\n",
    "}\n",
    "\n",
    "# create the directory that stores weights.pt\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSerror:\n",
    "        print('Error')\n",
    "createFolder('./models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c69c60ce-ca5d-4315-bbb0-a2ae48b7a8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '/opt/ml/input/data/eval'\n",
    "class Submission_Dataset(Dataset):\n",
    "    def __init__(self,subm_path):\n",
    "        self.subm_path = subm_path\n",
    "        self.df = pd.read_csv(os.path.join(self.subm_path,'info.csv'))\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self,idx):\n",
    "        X = Image.open(self.subm_path + '/images/' + self.df.loc[idx]['ImageID'])\n",
    "        X = transforms.CenterCrop(270)(X)\n",
    "        X = transforms.ToTensor()(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "baa9ae44-31c2-471f-90bd-354d1a7070b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_subm_dataset = Submission_Dataset(test_dir)\n",
    "ex_subm_dl = DataLoader(ex_subm_dataset,\n",
    "                        shuffle=False)\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "511ce5ff-dc28-4fd7-8a46-773e3ae6bb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14, current lr=0.0001\n",
      "Get best val_loss\n",
      "train loss: 0.335828, val loss: 0.674461, accuracy: 76.43, time: 1.9763 min\n",
      "----------\n",
      "Epoch 1/14, current lr=0.0001\n",
      "train loss: 0.269825, val loss: 0.732550, accuracy: 75.73, time: 3.9638 min\n",
      "----------\n",
      "Epoch 2/14, current lr=0.0001\n",
      "train loss: 0.216128, val loss: 0.757877, accuracy: 74.76, time: 5.9545 min\n",
      "----------\n",
      "Epoch 3/14, current lr=0.0001\n",
      "train loss: 0.181987, val loss: 0.908702, accuracy: 74.02, time: 7.9501 min\n",
      "----------\n",
      "Epoch 4/14, current lr=0.0001\n",
      "train loss: 0.146163, val loss: 0.939734, accuracy: 74.19, time: 9.9280 min\n",
      "----------\n",
      "Epoch 5/14, current lr=0.0001\n",
      "train loss: 0.119904, val loss: 1.051464, accuracy: 73.49, time: 11.9092 min\n",
      "----------\n",
      "Epoch 6/14, current lr=0.0001\n",
      "train loss: 0.103494, val loss: 1.014809, accuracy: 74.54, time: 13.9105 min\n",
      "----------\n",
      "Epoch 7/14, current lr=0.0001\n",
      "train loss: 0.077259, val loss: 1.139268, accuracy: 73.33, time: 15.9011 min\n",
      "----------\n",
      "Epoch 8/14, current lr=0.0001\n",
      "train loss: 0.071614, val loss: 1.251313, accuracy: 72.94, time: 17.8866 min\n",
      "----------\n",
      "Epoch 9/14, current lr=0.0001\n",
      "train loss: 0.063022, val loss: 1.281488, accuracy: 72.08, time: 19.8710 min\n",
      "----------\n",
      "Epoch 10/14, current lr=0.0001\n",
      "train loss: 0.054405, val loss: 1.391601, accuracy: 73.62, time: 21.8606 min\n",
      "----------\n",
      "Epoch 11/14, current lr=0.0001\n",
      "train loss: 0.050222, val loss: 1.337166, accuracy: 74.54, time: 23.8395 min\n",
      "----------\n",
      "Epoch 12/14, current lr=1e-05\n",
      "train loss: 0.029505, val loss: 1.288478, accuracy: 74.75, time: 25.8131 min\n",
      "----------\n",
      "Epoch 13/14, current lr=1e-05\n",
      "train loss: 0.021168, val loss: 1.271271, accuracy: 74.40, time: 27.7991 min\n",
      "----------\n",
      "Epoch 14/14, current lr=1e-05\n",
      "train loss: 0.019958, val loss: 1.308278, accuracy: 74.56, time: 29.7786 min\n",
      "----------\n",
      "******************************\n",
      "*#**#**#**#**#**#**#**#**#**#*\n",
      "******************************\n",
      "test inference is done!\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train)\n",
    "\n",
    "print('***'*10)\n",
    "print('*#*'*10)\n",
    "print('***'*10)\n",
    "\n",
    "all_predictions = []\n",
    "for images in ex_subm_dl:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_dir, 'new_submission05.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4c62ba5d-85db-4298-a4d6-d6b6aca348b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666b7bcf-2278-4fa9-8d0f-ec92b91af184",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
